# ğŸ“° Fake News Detection using NLP and Machine Learning

## ğŸ“Œ Overview

Fake news detection is a crucial challenge in the modern digital era. This project aims to build a machine learning pipeline that can effectively identify and classify news articles as **real** or **fake** using **Natural Language Processing (NLP)** techniques.

## ğŸ§  Techniques Used

- Natural Language Processing (NLP)
- Machine Learning Classifiers (SVM, Logistic Regression)
- Deep Learning (LSTM)
- Transformer-based Models (BERT)

---

## ğŸ“‚ Dataset

We used a publicly available dataset containing news articles labeled as either **fake** or **real**.

- **Columns:**
  - `title`: Headline of the news article
  - `text`: Full content of the news article
  - `label`: 1 for fake, 0 for real

---

## âš™ï¸ Project Structure

ğŸ“ fake-news-detection/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ fake_or_real_news.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA_and_Preprocessing.ipynb
â”‚ â”œâ”€â”€ ML_Models_SVM_LogReg.ipynb
â”‚ â”œâ”€â”€ LSTM_Model.ipynb
â”‚ â””â”€â”€ BERT_Model.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ saved_model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ app.py (optional for deployment)



---

## ğŸš€ Workflow

1. **Data Loading & Cleaning**
   - Handle missing values
   - Combine `title` and `text` columns

2. **Text Preprocessing**
   - Lowercasing
   - Removing punctuation and stopwords
   - Lemmatization

3. **Vectorization**
   - TF-IDF for traditional ML models
   - Tokenization for LSTM/BERT

4. **Model Building**
   - âœ… SVM and Logistic Regression
   - âœ… LSTM using Keras
   - âœ… BERT using HuggingFace Transformers

5. **Evaluation**
   - Accuracy, Precision, Recall, F1-score
   - Confusion Matrix

---

## ğŸ“Š Results

| Model            | Accuracy |
|------------------|----------|
| Logistic Regression | 92%      |
| SVM                  | 93%      |
| LSTM                 | 95%      |
| BERT                 | 97%      |

---

## ğŸ§ª Installation & Usage

### 1. Clone the repository
git clonehttps://github.com/purnapriya4448/codec_projects/edit/main/README.md fake-news-detection
2. Install dependencies

pip install -r requirements.txt
3. Run Jupyter Notebooks
You can run the notebooks for each model individually:

jupyter notebook notebooks/BERT_Model.ipynb
ğŸ–¥ï¸ Optional: Web App
A simple Flask app (app.py) is also provided to make predictions on custom input text

ğŸ§‘â€ğŸ”¬ Author
Purnapriya Tammana
Data Science Intern | NLP Enthusiast
ğŸ”— LinkedIn:https:https://www.linkedin.com/in/purnapriya-tammana-27a0a7346
ğŸ”— GitHub:https://github.com/purnapriya4448/codec_projects


ğŸ“œ License
This project is open-source and available under the MIT License.

ğŸ™Œ Acknowledgments
Dataset: Kaggle â€“ Fake and Real News Dataset

Libraries: Scikit-learn, TensorFlow, HuggingFace Transformers, NLTK, Flask
# project 2: Customer Churn Prediction using Machine Learning

## Overview

Customer churn is when a customer stops using a company's products or services. Predicting churn helps businesses proactively retain customers and reduce revenue loss. This project aims to predict whether a customer will churn based on historical usage patterns and demographics using supervised machine learning techniques.

## Goals

- Analyze customer behavior
- Identify key churn indicators
- Build a predictive model with high accuracy
- Deploy the model for real-time predictions (optional)

---

## Dataset

We use a telecom dataset containing customer information, services used, and whether they have churned.

### Key Features:
- `gender`, `SeniorCitizen`, `Partner`, `Dependents`
- `tenure`, `MonthlyCharges`, `TotalCharges`
- `Contract`, `PaymentMethod`, `InternetService`, etc.
- `Churn` (Target variable: Yes = 1, No = 0)

---

## Project Structure
ğŸ“ customer-churn-prediction/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ churn_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA_and_Cleaning.ipynb
â”‚ â”œâ”€â”€ Churn_Model_Training.ipynb
â”‚ â””â”€â”€ Churn_Model_Evaluation.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ churn_model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ app.py # Flask app (optional)



## Workflow

1. **Data Preprocessing**
   - Handle missing values
   - Encode categorical features (Label Encoding / One-Hot Encoding)
   - Scale numerical features

2. **Exploratory Data Analysis (EDA)**
   - Correlation matrix
   - Churn vs. categorical and numerical features

3. **Modeling**
   - Logistic Regression
   - Random Forest
   - XGBoost
   - Evaluate using Accuracy, Precision, Recall, F1-score, ROC AUC

4. **Hyperparameter Tuning**
   - GridSearchCV / RandomizedSearchCV

5. **Model Deployment (Optional)**
   - Flask app to predict churn on new customer data

---

## Results

| Model             | Accuracy | ROC AUC |
|------------------|----------|---------|
| Logistic Regression | 80%     | 0.85    |
| Random Forest        | 85%     | 0.88    |
| XGBoost              | 87%     | 0.90    |

---

## Installation

```bash
git clone https://github.com/your-username/customer-churn-prediction.git
cd customer-churn-prediction
pip install -r requirements.txt
Run the notebook:

jupyter notebook notebooks/Churn_Model_Training.ipynb
Web App (Optional)
To run the Flask app:

python app.py
Author
Purnapriya Tammana
Data Science Intern
LinkedIn:https://www.linkedin.com/in/purnapriya-tammana-27a0a7346/
 GitHub:https://github.com/purnapriya4448/codec_projects/edit/main/README.md

License
This project is licensed under the MIT License.

Acknowledgments
Dataset: Kaggle â€“ Telco Customer Churn

Tools: Scikit-learn, Pandas, Matplotlib, Seaborn, Flask, XGBoost


